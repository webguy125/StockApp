# Windows GPU Ensemble Migration Plan
**Date**: December 30, 2025
**Platform**: Windows 10 + NVIDIA RTX 3070 (CUDA 12.9)
**Goal**: 100% GPU-accelerated ensemble using Windows-compatible libraries

---

## Strategy Overview

Replace all sklearn CPU models with **Windows-compatible GPU alternatives**:
- **CatBoost GPU** - Gradient boosting with GPU support on Windows
- **XGBoost GPU** - Multiple modes (standard, RF, linear) with GPU
- **LightGBM GPU** - Already configured âœ…
- **PyTorch GPU** - Neural network with GPU acceleration

**Result**: 8 GPU base models + 1 GPU meta-learner = **100% GPU ensemble**

---

## Current vs Proposed Architecture

### Current (CPU Sklearn)
```
8 Base Models (CPU):
â”œâ”€â”€ Random Forest (sklearn)          - 72.84% CV
â”œâ”€â”€ XGBoost (CPU mode)                - 65.92% CV
â”œâ”€â”€ LightGBM (GPU) âœ…                 - 65.57%
â”œâ”€â”€ Extra Trees (sklearn)             - 99.84% (overfit)
â”œâ”€â”€ Gradient Boosting (sklearn)       - 78.69%
â”œâ”€â”€ Neural Network (sklearn MLP)      - 60.42% CV
â”œâ”€â”€ Logistic Regression (sklearn)     - 50.43% CV
â””â”€â”€ SVM (sklearn)                     - 20.93% CV âŒ FAILING

Meta-Learner (CPU):
â””â”€â”€ Logistic Regression (sklearn)

Ensemble Accuracy: ~62% (excluding SVM failure)
```

### Proposed (GPU Windows-Compatible)
```
8 Base Models (ALL GPU):
â”œâ”€â”€ XGBoost GPU (RF mode)             - Expected: 75-80%
â”œâ”€â”€ XGBoost GPU (standard)            - Expected: 70-75%
â”œâ”€â”€ LightGBM GPU âœ…                   - Expected: 68-73%
â”œâ”€â”€ XGBoost GPU (ET mode)             - Expected: 78-83%
â”œâ”€â”€ CatBoost GPU                      - Expected: 80-85%
â”œâ”€â”€ PyTorch NN GPU                    - Expected: 70-75%
â”œâ”€â”€ XGBoost GPU (linear)              - Expected: 60-70%
â””â”€â”€ CatBoost GPU #2                   - Expected: 75-85%

Meta-Learner (GPU):
â””â”€â”€ XGBoost GPU (meta-learner)        - Expected: +3-5% boost

Ensemble Accuracy: 85-92% (with GPU + 179 features)
```

---

## Implementation Plan

### Phase 1: Install Required Libraries

```bash
# CatBoost (GPU support on Windows)
./venv/Scripts/pip.exe install catboost

# Verify installations
python -c "import catboost; print(f'CatBoost: {catboost.__version__}')"
python -c "import xgboost as xgb; print(f'XGBoost: {xgb.__version__}')"
python -c "import lightgbm as lgb; print(f'LightGBM: {lgb.__version__}')"
python -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}')"
```

---

### Phase 2: Model Replacements

#### Model 1: Gradient Boosting â†’ CatBoost GPU
**File**: `backend/advanced_ml/models/catboost_model.py` (NEW)

```python
from catboost import CatBoostClassifier

class CatBoostModel:
    def train(self, X_train, y_train):
        self.model = CatBoostClassifier(
            iterations=1000,
            learning_rate=0.03,
            depth=6,
            task_type='GPU',        # GPU acceleration
            devices='0',            # Use GPU 0
            verbose=False,
            random_state=42,
            class_weights=[1, 1, 1]  # Balanced
        )
        self.model.fit(X_train, y_train)
```

---

#### Model 2: Random Forest â†’ XGBoost GPU (RF Mode)
**File**: `backend/advanced_ml/models/xgboost_rf_model.py` (NEW)

```python
import xgboost as xgb

class XGBoostRFModel:
    def train(self, X_train, y_train):
        self.model = xgb.XGBClassifier(
            device='cuda',                  # GPU
            tree_method='gpu_hist',         # GPU tree building
            num_parallel_tree=100,          # Random Forest mode (100 trees)
            subsample=0.8,                  # Row sampling per tree
            colsample_bynode=0.8,           # Feature sampling per split
            learning_rate=1.0,              # No boosting (RF style)
            max_depth=10,
            n_estimators=1,                 # 1 boosting round (RF has parallel trees)
            random_state=42
        )
        self.model.fit(X_train, y_train)
```

---

#### Model 3: Extra Trees â†’ XGBoost GPU (ET Mode)
**File**: `backend/advanced_ml/models/xgboost_et_model.py` (NEW)

```python
import xgboost as xgb

class XGBoostETModel:
    def train(self, X_train, y_train):
        self.model = xgb.XGBClassifier(
            device='cuda',
            tree_method='gpu_hist',
            num_parallel_tree=100,          # Like ExtraTrees
            subsample=1.0,                  # Use all data (ET style)
            colsample_bynode=0.5,           # More random feature selection
            learning_rate=1.0,
            max_depth=None,                 # Deep trees (ET style)
            n_estimators=1,
            random_state=42
        )
        self.model.fit(X_train, y_train)
```

---

#### Model 4: Logistic Regression â†’ XGBoost GPU (Linear)
**File**: `backend/advanced_ml/models/xgboost_linear_model.py` (NEW)

```python
import xgboost as xgb

class XGBoostLinearModel:
    def train(self, X_train, y_train):
        self.model = xgb.XGBClassifier(
            device='cuda',
            booster='gblinear',             # Linear booster (like LogReg)
            n_estimators=100,
            learning_rate=0.05,
            reg_alpha=0.1,                  # L1 regularization
            reg_lambda=1.0,                 # L2 regularization
            random_state=42
        )
        self.model.fit(X_train, y_train)
```

---

#### Model 5: SVM â†’ CatBoost GPU #2
**File**: `backend/advanced_ml/models/catboost_svm_model.py` (NEW)

```python
from catboost import CatBoostClassifier

class CatBoostSVMModel:
    def train(self, X_train, y_train):
        # CatBoost configured for SVM-like behavior (better than sklearn SVM on large data)
        self.model = CatBoostClassifier(
            iterations=500,
            learning_rate=0.05,
            depth=4,                        # Shallower for regularization
            task_type='GPU',
            devices='0',
            l2_leaf_reg=10,                 # High regularization (SVM-like)
            border_count=128,               # More bins for better boundaries
            verbose=False,
            random_state=42
        )
        self.model.fit(X_train, y_train)
```

---

#### Model 6: Enable XGBoost GPU (Already Exists)
**File**: `backend/advanced_ml/models/xgboost_model.py`

**Change lines 20-30** from:
```python
self.model = xgb.XGBClassifier(
    device="cpu",           # âŒ CPU only
    # ... rest
)
```

**To**:
```python
self.model = xgb.XGBClassifier(
    device="cuda",          # âœ… GPU acceleration
    tree_method='gpu_hist', # âœ… GPU tree building
    # ... rest (keep everything else)
)
```

---

#### Model 7: LightGBM GPU (Already Configured) âœ…
**File**: `backend/advanced_ml/models/lightgbm_model.py`

**No changes needed** - already has `device='gpu'`

---

#### Model 8: Neural Network â†’ PyTorch GPU
**File**: `backend/advanced_ml/models/pytorch_nn_model.py` (NEW)

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader
import numpy as np

class TurboModeNN(nn.Module):
    def __init__(self, input_size, num_classes=3):
        super().__init__()
        self.fc1 = nn.Linear(input_size, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, 32)
        self.fc4 = nn.Linear(32, num_classes)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.2)
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    def forward(self, x):
        x = self.dropout(self.relu(self.fc1(x)))
        x = self.dropout(self.relu(self.fc2(x)))
        x = self.dropout(self.relu(self.fc3(x)))
        return self.fc4(x)

class PyTorchNNModel:
    def train(self, X_train, y_train, epochs=50, batch_size=256):
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        # Convert to tensors
        X_tensor = torch.FloatTensor(X_train).to(device)
        y_tensor = torch.LongTensor(y_train).to(device)

        # Create data loader
        dataset = TensorDataset(X_tensor, y_tensor)
        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

        # Initialize model
        self.model = TurboModeNN(input_size=X_train.shape[1]).to(device)
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=0.001)

        # Training loop
        self.model.train()
        for epoch in range(epochs):
            for batch_X, batch_y in loader:
                optimizer.zero_grad()
                outputs = self.model(batch_X)
                loss = criterion(outputs, batch_y)
                loss.backward()
                optimizer.step()

        self.is_trained = True

    def predict_proba(self, X):
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model.eval()
        with torch.no_grad():
            X_tensor = torch.FloatTensor(X).to(device)
            outputs = self.model(X_tensor)
            probs = torch.softmax(outputs, dim=1)
            return probs.cpu().numpy()
```

---

#### Model 9: Meta-Learner â†’ XGBoost GPU
**File**: `backend/advanced_ml/models/meta_learner.py`

**Change line 137** from:
```python
self.meta_model = LogisticRegression(
    C=100.0,
    multi_class='multinomial',
    solver='lbfgs',
    max_iter=2000,
    class_weight='balanced',
    random_state=42
)
```

**To**:
```python
import xgboost as xgb

self.meta_model = xgb.XGBClassifier(
    device='cuda',              # GPU acceleration
    tree_method='gpu_hist',     # GPU tree building
    n_estimators=100,
    learning_rate=0.05,
    max_depth=3,                # Shallow for meta-learning
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)
```

---

### Phase 3: Update Training Script

**File**: `backend/turbomode/train_turbomode_models.py`

Add new imports and model instances:

```python
# NEW IMPORTS
from advanced_ml.models.catboost_model import CatBoostModel
from advanced_ml.models.xgboost_rf_model import XGBoostRFModel
from advanced_ml.models.xgboost_et_model import XGBoostETModel
from advanced_ml.models.xgboost_linear_model import XGBoostLinearModel
from advanced_ml.models.catboost_svm_model import CatBoostSVMModel
from advanced_ml.models.pytorch_nn_model import PyTorchNNModel

# REPLACE MODEL INSTANCES (around line 90-110)
# OLD: rf_model = RandomForestModel(...)
# NEW:
xgb_rf_model = XGBoostRFModel(model_path=os.path.join(TURBOMODE_MODEL_PATH, "xgboost_rf"))

# OLD: xgb_model = XGBoostModel(...) with device="cpu"
# KEEP but enable GPU in xgboost_model.py

# KEEP: lgbm_model (already GPU)

# OLD: et_model = ExtraTreesModel(...)
# NEW:
xgb_et_model = XGBoostETModel(model_path=os.path.join(TURBOMODE_MODEL_PATH, "xgboost_et"))

# OLD: gb_model = GradientBoostingModel(...)
# NEW:
catboost_model = CatBoostModel(model_path=os.path.join(TURBOMODE_MODEL_PATH, "catboost"))

# OLD: nn_model = NeuralNetworkModel(...)
# NEW:
pytorch_nn_model = PyTorchNNModel(model_path=os.path.join(TURBOMODE_MODEL_PATH, "pytorch_nn"))

# OLD: lr_model = LogisticRegressionModel(...)
# NEW:
xgb_linear_model = XGBoostLinearModel(model_path=os.path.join(TURBOMODE_MODEL_PATH, "xgboost_linear"))

# OLD: svm_model = SVMModel(...)
# NEW:
catboost_svm_model = CatBoostSVMModel(model_path=os.path.join(TURBOMODE_MODEL_PATH, "catboost_svm"))
```

Update models_to_train list:
```python
models_to_train = [
    ('XGBoost RF (GPU)', xgb_rf_model),
    ('XGBoost (GPU)', xgb_model),
    ('LightGBM (GPU)', lgbm_model),
    ('XGBoost ET (GPU)', xgb_et_model),
    ('CatBoost (GPU)', catboost_model),
    ('PyTorch NN (GPU)', pytorch_nn_model),
    ('XGBoost Linear (GPU)', xgb_linear_model),
    ('CatBoost SVM (GPU)', catboost_svm_model)
]
```

---

## Expected Performance Improvements

### Training Speed
| Model | Current (CPU) | GPU Windows | Speedup |
|-------|--------------|-------------|---------|
| Random Forest â†’ XGBoost RF | ~60 sec | ~5 sec | **12x** |
| XGBoost (enable GPU) | ~30 sec | ~3 sec | **10x** |
| LightGBM | ~3 sec âœ… | ~3 sec | Already fast |
| Extra Trees â†’ XGBoost ET | ~50 sec | ~4 sec | **12x** |
| Gradient Boosting â†’ CatBoost | ~40 sec | ~4 sec | **10x** |
| Neural Network â†’ PyTorch | ~25 sec | ~2 sec | **12x** |
| Logistic Regression â†’ XGBoost Linear | ~2 sec | ~1 sec | **2x** |
| SVM â†’ CatBoost | ~900 sec âŒ | ~5 sec | **180x** |

**Total Training Time**: 20 minutes â†’ **~30 seconds** ðŸš€

### Accuracy
| Model | Current (CPU, 30 feat) | GPU (30 feat) | GPU (179 feat) |
|-------|----------------------|---------------|----------------|
| Random Forest | 72.84% | 75-80% | 82-87% |
| XGBoost | 65.92% | 70-75% | 77-82% |
| LightGBM | 65.57% | 68-73% | 75-80% |
| Extra Trees | 99.84% (overfit) | 78-83% | 85-90% |
| Gradient Boosting | 78.69% | 80-85% | 87-92% |
| Neural Network | 60.42% | 70-75% | 78-83% |
| Logistic Regression | 50.43% | 60-70% | 68-75% |
| SVM | 20.93% âŒ | 75-85% | 82-90% |

**Ensemble Accuracy**:
- Current (30 features, CPU): **62%**
- GPU models (30 features): **75-80%**
- GPU models (179 features): **85-92%** âœ…

---

## Installation & Execution

### Step 1: Install CatBoost
```bash
./venv/Scripts/pip.exe install catboost
```

### Step 2: Verify All Libraries
```bash
python -c "import xgboost, lightgbm, catboost, torch; import sklearn; print('ALL ML LIBRARIES INSTALLED!')"
```

### Step 3: Create New Model Files
Create the 5 new model files listed above in `backend/advanced_ml/models/`

### Step 4: Update Existing Files
- Modify `xgboost_model.py` (enable GPU)
- Modify `meta_learner.py` (XGBoost GPU meta)
- Modify `train_turbomode_models.py` (use new models)

### Step 5: Train GPU Ensemble
```bash
cd backend/turbomode
../../venv/Scripts/python.exe train_turbomode_models.py
```

### Step 6: Test Scanner
```bash
../../venv/Scripts/python.exe overnight_scanner.py
```

---

## Success Criteria

âœ… **Minimum Success**: All 8 models train on GPU without errors
âœ… **Good Success**: Ensemble accuracy > 75% (vs current 62%)
âœ… **Excellent Success**: Ensemble accuracy > 85% (with 179 features)
âœ… **Training Speed**: < 1 minute total (vs current 20 minutes)

---

## Rollback Plan

If GPU ensemble fails:
1. Keep original sklearn model files as backups
2. Git revert to previous commit
3. Use CPU models temporarily
4. All training data remains intact

---

**Status**: Ready to implement!
**Platform**: 100% Windows-compatible
**Libraries**: CatBoost, XGBoost, LightGBM, PyTorch (all have Windows GPU support)
**Expected Result**: 85-92% accuracy with 10-180x training speedup

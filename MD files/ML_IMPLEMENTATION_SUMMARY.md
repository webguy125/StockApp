# Triad Trend Pulse ML Implementation Summary

**Date**: November 16, 2025

## Overview

This document outlines the Machine Learning infrastructure for the Triad Trend Pulse indicator, enabling ML-powered pivot reliability scoring.

## Architecture

### Core Components

1. **Data Storage** (`backend/ml/data_storage.py`)
   - SQLite database for OHLCV + indicator outputs
   - Schema optimized for time-series queries
   - 30-day retention for 1min data, 3 years for daily

2. **Data Fetching** (`backend/ml/data_fetcher.py`)
   - Crypto: ccxt.coinbasepro for historical backfill
   - Stocks: yfinance for historical data
   - Auto-detection based on symbol format

3. **Feature Engineering** (`backend/ml/feature_engineering.py`)
   - Pure Python implementations (no TA-Lib dependency)
   - 9 features: oscillator, weighted_trend, short_trend, adx, volume_change, atr, rsi, momentum, timeframe
   - Reuses logic from frontend indicator

4. **ML Model** (`backend/ml/pivot_model.py`)
   - PyTorch MLP: 9 → 32 → 16 → 1 (Sigmoid)
   - Binary classification for pivot reliability
   - Model file: `backend/ml/models/pivot_model.pth`

5. **Training Pipeline** (`backend/ml/train_pivot_model.py`)
   - Fetch multi-asset, multi-timeframe data
   - Generate labels: 5% reversal in 10 bars
   - Balance samples across timeframes
   - Early stopping, save best model

6. **Flask API** (`backend/api_server.py`)
   - New endpoint: `POST /ml/pivot-reliability`
   - Input: feature array [9 values]
   - Output: probability score [0-1]

## Database Schema

```sql
CREATE TABLE ohlcv (
    timestamp DATETIME NOT NULL,
    asset TEXT NOT NULL,
    open REAL,
    high REAL,
    low REAL,
    close REAL,
    volume REAL,
    -- Indicator outputs
    triad_weighted_trend REAL,
    triad_oscillator REAL,
    triad_short_trend REAL,
    triad_pivot_high INTEGER,
    triad_pivot_low INTEGER,
    triad_pivot_score REAL,
    PRIMARY KEY (timestamp, asset)
);

CREATE INDEX idx_asset_timestamp ON ohlcv (asset, timestamp);
CREATE INDEX idx_timestamp ON ohlcv (timestamp);
```

## Workflow

### Training (Offline)

1. Fetch historical data for multiple assets
2. Compute features for all timeframes
3. Generate pivot labels (5% reversal detection)
4. Train PyTorch model
5. Save to `pivot_model.pth`

### Inference (Real-time)

1. Frontend calculates indicator for current data
2. For each pivot detected, extract 9 features
3. POST to `/ml/pivot-reliability` endpoint
4. Receive ML score (0-1)
5. Filter pivots with score > 0.7
6. Display high-confidence pivots only

## Dependencies

- `torch` - PyTorch for ML model
- `ccxt` - Coinbase historical data
- `yfinance` - Stock historical data
- `pandas`, `numpy` - Data manipulation
- `sqlite3` - Built-in database

## File Structure

```
backend/
  ml/
    __init__.py                 ✅ Created (exports all ML functions)
    data_storage.py             ✅ Created (381 lines - SQLite CRUD)
    data_fetcher.py             ✅ Created (340 lines - yfinance + ccxt)
    timeframe_aggregator.py     ✅ Created (266 lines - pandas resample)
    feature_engineering.py      ✅ Created (560 lines - pure Python indicators)
    pivot_model.py              ✅ Created (246 lines - PyTorch MLP)
    train_pivot_model.py        ✅ Created (470 lines - full training pipeline)
    models/
      pivot_model.pth           ⏳ Generated by training (run train_pivot_model.py)
  api_server.py                 ✅ ML endpoints added (lines 1296-1407)

frontend/
  js/indicators/TriadTrendPulse/
    TriadTrendPulse.js          ✅ Updated (ML integration added)
```

## Current Progress

### ✅ ALL MODULES COMPLETED

1. **data_storage.py** (381 lines)
   - Full SQLite schema with indexes
   - CRUD operations for OHLCV data
   - Indicator output storage/retrieval
   - Bulk insert optimization
   - Data cleanup utilities
   - Singleton pattern for efficiency

2. **data_fetcher.py** (340 lines)
   - yfinance integration for stocks
   - ccxt integration for crypto
   - Auto-detection of asset type
   - Chunked fetching for large datasets
   - Rate limiting handling
   - Real-time data append function

3. **timeframe_aggregator.py** (266 lines)
   - Pandas resample for all 12 timeframes
   - Proper OHLCV aggregation rules
   - Indicator column handling with mean aggregation
   - Timeframe encoding (1-12 integers)

4. **feature_engineering.py** (560 lines)
   - Pure Python RSI, ATR, ADX implementations
   - 9 ML features computation
   - Timeframe encoding
   - Batch processing for multiple assets
   - Feature validation

5. **pivot_model.py** (246 lines)
   - PyTorch MLP architecture (9 → 32 → 16 → 1)
   - Model save/load utilities
   - Inference functions
   - Singleton pattern for Flask API

6. **train_pivot_model.py** (470 lines)
   - Multi-asset data loading (3 crypto + 5 stocks)
   - Multi-timeframe processing
   - Label generation (5% reversal in 10 bars)
   - Training loop with validation split (70/30)
   - Early stopping (patience=10)
   - Model persistence to models/pivot_model.pth

7. **API endpoints** (111 lines in api_server.py)
   - POST /ml/pivot-reliability - Inference endpoint
   - GET /ml/model-info - Model metadata
   - Lazy model loading
   - JSON request/response handling

8. **Frontend Integration** (120+ lines in TriadTrendPulse.js)
   - Async ML enhancement method
   - Feature extraction from indicator data
   - Threshold-based pivot filtering
   - Graceful fallback to default scores

## Integration Points

1. **Frontend Indicator** (`TriadTrendPulse.js`)
   - Enable ML via `use_ml` setting
   - Call ML endpoint for pivot scoring
   - Display ML scores in visualization

2. **Backend API** (`api_server.py`)
   - Load model on startup
   - Singleton pattern for model instance
   - Fast inference (<10ms per request)

## Performance Considerations

- **Training**: CPU-intensive, 10-30 minutes for full dataset
- **Inference**: <10ms per pivot (model loaded in memory)
- **Database**: Indexed queries, bulk inserts
- **Memory**: float32 for OHLCV, chunked processing for large datasets

## Usage Instructions

### 1. Train the Model

```bash
cd backend/ml
python train_pivot_model.py
```

This will:
- Fetch historical data for 8 assets (3 crypto + 5 stocks)
- Process 5 timeframes (5min, 15min, 1h, 4h, 1d)
- Generate ~2000-5000 pivot samples
- Train for up to 100 epochs with early stopping
- Save best model to `models/pivot_model.pth`

Expected training time: 10-30 minutes on CPU

### 2. Enable ML in the Frontend

In the indicator settings for Triad Trend Pulse:
- Toggle `use_ml` to **true**
- Set `ml_threshold` to 0.7 (70% confidence minimum)

### 3. Verify ML Integration

Check the browser console for:
```
✅ ML enhanced 15 pivots, kept 8
```

And check the Flask server logs for:
```
✅ ML model loaded successfully
```

### 4. API Testing

Test the ML endpoint directly:
```bash
curl -X POST http://127.0.0.1:5000/ml/pivot-reliability \
  -H "Content-Type: application/json" \
  -d '{"features": [[0.5, 0.3, 0.2, 0.6, 0.4, 0.01, 0.55, 0.6, 0.75]]}'
```

Expected response:
```json
{"scores": [0.847], "count": 1}
```

### 5. Model Retraining

To retrain with new data or parameters:
1. Edit `TRAINING_CONFIG` in `train_pivot_model.py`
2. Run training script again
3. Restart Flask server to load new model

## Notes

- Model training should be done offline (not in production)
- Consider upgrading to TimescaleDB for production (better time-series performance)
- PyTorch is large (~2GB) - ensure sufficient disk space
- TA-Lib avoided due to Windows installation complexity
